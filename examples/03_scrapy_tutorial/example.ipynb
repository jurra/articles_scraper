{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit (conda)"
  },
  "interpreter": {
   "hash": "340f02591a7034ba7d2cf0b9a658107515607a6c0350022309aeac3c493634d7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "### crud.py ###\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import pandas\n",
    "from tutorial.models import *\n",
    "\n",
    "from datetime import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Create the connection\n",
    "engine = db_connect()\n",
    "create_table(engine)\n",
    "Session = sessionmaker(bind=engine)\n",
    "s = Session()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# query articles in database\n",
    "articles = s.query(Article).all()\n",
    "for article in articles:\n",
    "    print(article.title)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OCR and Machine Translation\n",
      "OCR and Machine Translation\n",
      "Editing Audio with Audacity\n",
      "Downloading Multiple Records Using Query Strings\n",
      "Fetching and Parsing Data from the Web with OpenRefine\n",
      "From HTML to List of Words (part 2)\n",
      "From HTML to List of Words (part 1)\n",
      "Using Gazetteers to Extract Sets of Keywords from Free-Flowing Texts\n",
      "Extracting Illustrated Pages from Digital Libraries with Python\n",
      "Generating an Ordered Data Set from an OCR Text File\n",
      "Exploring and Analyzing Network Data with Python\n",
      "Detecting Text Reuse with Passim\n",
      "Dealing with Big Data and Network Analysis Using Neo4j\n",
      "Data Mining the Internet Archive Collection\n",
      "Data Wrangling and Management in R\n",
      "Crowdsourced-Data Normalization with Python and Pandas\n",
      "From Hermeneutics to Data to Networks: Data Extraction and Network Visualization of Historical Sources\n",
      "Downloading Web Pages with Python\n",
      "Working with batches of PDF files\n",
      "Setting Up an Integrated Development Environment for Python (Windows)\n",
      "Visualizing Data with Bokeh and Pandas\n",
      "Understanding Web Pages and HTML\n",
      "Creating New Vector Layers in QGIS 2.0\n",
      "Using JavaScript to Create Maps of Correspondence\n",
      "Up and Running with Omeka.net\n",
      "Working with Text Files in Python\n",
      "Understanding Regular Expressions\n",
      "Transforming Data for Reuse and Re-publication with XML and XSL\n",
      "Getting Started with Topic Modeling and MALLET\n",
      "Text Mining in Python through the HTRC Feature Reader\n",
      "Temporal Network Analysis with R\n",
      "Sustainable Authorship in Plain Text using Pandoc and Markdown\n",
      "The Sound of Data (a gentle introduction to sonification for historians)\n",
      "Transliterating non-ASCII characters with Python\n",
      "Sentiment Analysis for Exploratory Data Analysis\n",
      "R Basics with Tabular Data\n",
      "Output Data as an HTML File with Python\n",
      "Normalizing Textual Data with Python\n",
      "Counting and mining research data with Unix\n",
      "Installing QGIS 2.0 and Adding Layers\n",
      "Output Keywords in Context in an HTML File with Python\n",
      "Preserving Your Research Data\n",
      "Keywords in Context (Using n-grams) with Python\n",
      "Reshaping JSON with jq\n",
      "Web Mapping with Python and Leaflet\n",
      "Setting up an Integrated Development Environment for Python (Linux)\n",
      "Introduction to Jupyter Notebooks\n",
      "Manipulating Strings in Python\n",
      "Setting Up an Integrated Development Environment for Python (Mac)\n",
      "Supervised Classification: The Naive Bayesian Returns to the Old Bailey\n",
      "Introduction to stylometry with Python\n",
      "Python Introduction and Installation\n",
      "Introduction to the Principles of Linked Open Data\n",
      "Introduction to the Windows Command Line with PowerShell\n",
      "An Introduction to Twitterbots with Tracery\n",
      "Introduction to Populating a Website with API Data\n",
      "Intro to Beautiful Soup\n",
      "Introduction to Audiovisual Transcoding, Editing, and Color Analysis with FFmpeg\n",
      "Getting Started with Markdown\n",
      "Introduction to the Bash Command Line\n",
      "Installing Omeka\n",
      "Installing Python Modules with pip\n",
      "Introduction to MySQL with R\n",
      "Intro to Google Maps and Google Earth\n",
      "Introduction to Gravity Models of Migration & Trade\n",
      "Geocoding Historical Data using QGIS\n",
      "Creating Web APIs with Python and Flask\n",
      "Creating an Omeka Exhibit\n",
      "Using Geospatial Data to Inform Historical Research in R\n",
      "Georeferencing in QGIS 2.0\n",
      "Creating Mobile Augmented Reality Experiences in Unity\n",
      "Counting Word Frequencies with Python\n",
      "Correspondence Analysis for Historical Research with R\n",
      "Corpus Analysis with Antconc\n",
      "Understanding and Using Common Similarity Measures for Text Analysis\n",
      "Geoparsing English-Language Text with the Edinburgh Geoparser\n",
      "Creating and Viewing HTML Files with Python\n",
      "Basic Text Processing in R\n",
      "Automated Downloading with Wget\n",
      "Cleaning OCRâ€™d text with Regular Expressions\n",
      "Cleaning Data with OpenRefine\n",
      "Building a static website with Jekyll and GitHub Pages\n",
      "Beginner's Guide to Twitter Data\n",
      "Code Reuse and Modularity in Python\n",
      "Running a Collaborative Research Website and Blog with Jekyll and GitHub\n",
      "Applied Archival Downloading with Wget\n",
      "Analyzing Documents with TF-IDF\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "authors = s.query(Author).all()\n",
    "for author in authors:\n",
    "    print(author.name)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fidelia Ponce\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Base.metadata.drop_all(cnx)\n",
    "# close session and connection\n",
    "s.close_all()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-5-034c853e53f1>:3: SADeprecationWarning: The Session.close_all() method is deprecated and will be removed in a future release.  Please refer to session.close_all_sessions().\n",
      "  s.close_all()\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}